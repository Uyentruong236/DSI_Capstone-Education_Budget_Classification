{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "budget_train = pd.read_csv('../data/train_cleaned.csv', index_col=0)\n",
    "budget_test = pd.read_csv('../data/test_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function                      0\n",
       "Use                           0\n",
       "Sharing                       0\n",
       "Reporting                     0\n",
       "Student_Type                  0\n",
       "Position_Type                 0\n",
       "Object_Type                   0\n",
       "Pre_K                         0\n",
       "Operating_Status              0\n",
       "Object_Description          423\n",
       "Text_2                       17\n",
       "SubFund_Description           0\n",
       "Job_Title_Description         0\n",
       "Text_3                    70814\n",
       "Text_4                       18\n",
       "Sub_Object_Description        0\n",
       "Location_Description          0\n",
       "FTE                           0\n",
       "Function_Description          5\n",
       "Facility_or_Department        0\n",
       "Position_Extra              611\n",
       "Total                         0\n",
       "Program_Description           2\n",
       "Fund_Description              0\n",
       "Text_1                      422\n",
       "combined_text                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            0\n",
       "Object_Description         1752\n",
       "Program_Description        5253\n",
       "SubFund_Description       33953\n",
       "Job_Title_Description     17747\n",
       "Facility_or_Department    47225\n",
       "Sub_Object_Description    16452\n",
       "Location_Description      12748\n",
       "FTE                           0\n",
       "Function_Description       3198\n",
       "Position_Extra            36279\n",
       "Text_4                    47252\n",
       "Total                         0\n",
       "Text_2                    45426\n",
       "Text_3                    44281\n",
       "Fund_Description          10478\n",
       "Text_1                    34717\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in budget_test[word_predictors]:\n",
    "    budget_test[col] = budget_test[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in budget_train[word_predictors]:\n",
    "    budget_train[col] = budget_train[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    The data is expected to be stored in a 2D data structure, where the first\n",
    "    index is over features and the second is over samples.  i.e.\n",
    "\n",
    "    >> len(data[key]) == n_samples\n",
    "\n",
    "    Please note that this is the opposite convention to scikit-learn feature\n",
    "    matrixes (where the first index corresponds to sample).\n",
    "\n",
    "    ItemSelector only requires that the collection implement getitem\n",
    "    (data[key]).  Examples include: a dict of lists, 2D numpy array, Pandas\n",
    "    DataFrame, numpy record array, etc.\n",
    "\n",
    "    >> data = {'a': [1, 5, 2, 5, 2, 8],\n",
    "               'b': [9, 4, 1, 4, 1, 3]}\n",
    "    >> ds = ItemSelector(key='a')\n",
    "    >> data['a'] == ds.transform(data)\n",
    "\n",
    "    Parameters\n",
    "     ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 400,000+ examples, 14 features\n",
    "X = budget_train[predictors] \n",
    "y = label.fit_transform(budget_train['Operating_Status'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .2, random_state=42)\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature union transformer list \n",
    "transformer_list = [\n",
    "    ('Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_2', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_2')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('SubFund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='SubFund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Job_Title_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Job_Title_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_3', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_3')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_4', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_4')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Sub_Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Sub_Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Location_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Location_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Function_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Function_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Facility_or_Department', Pipeline([\n",
    "                ('selector', ItemSelector(key='Facility_or_Department')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Position_Extra', Pipeline([\n",
    "                ('selector', ItemSelector(key='Position_Extra')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Program_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Program_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Fund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Fund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_1', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_1')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't include numerical columns in final feature union since it decreased scores and increased log loss- in general, in the original data, numerical features had a lot of missing values and some incorrect values for data that were there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " lr_pipe_1 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", LogisticRegression())])\n",
    "\n",
    "lr_pipe_2 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", LogisticRegression(C=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('Object_Description', Pipeline(steps=[('selector', ItemSelector(key='Object_Description')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe_1.fit(X_train,y_train)\n",
    "lr_pipe_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr1_predict_proba = lr_pipe_1.predict_proba(X_val)\n",
    "lr2_predict_proba = lr_pipe_2.predict_proba(X_val)\n",
    "combine_pred = np.concatenate([lr1_predict_proba, lr2_predict_proba], axis=1)\n",
    "\n",
    "combined_model = RandomForestClassifier()\n",
    "combined_model.fit(combine_pred, y_val)\n",
    "\n",
    "final_prediction = combined_model.predict_proba(combine_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops_result = [{\"target\": \"Operating_Status\",\n",
    "             \"log_loss\": log_loss(y_val, final_prediction)\n",
    "             }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops_blended = pd.DataFrame(ops_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops_blended.to_pickle('ops_blended.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0431921279842\n",
      "0.0392067274596\n",
      "0.0234843715258\n"
     ]
    }
   ],
   "source": [
    "print(log_loss(y_val, lr1_predict_proba))\n",
    "print(log_loss(y_val, lr2_predict_proba))\n",
    "print(log_loss(y_val, final_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_K = pd.read_pickle('../ipynb/prek_blended.pkl')\n",
    "use = pd.read_pickle('../ipynb/use_blended.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_loss</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023484</td>\n",
       "      <td>Operating_Status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013780</td>\n",
       "      <td>Pre_K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039473</td>\n",
       "      <td>Use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_loss            target\n",
       "0  0.023484  Operating_Status\n",
       "1  0.013780             Pre_K\n",
       "2  0.039473               Use"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([ops_blended, pre_K, use], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Function',\n",
       " 'Use',\n",
       " 'Sharing',\n",
       " 'Reporting',\n",
       " 'Student_Type',\n",
       " 'Position_Type',\n",
       " 'Object_Type',\n",
       " 'Pre_K',\n",
       " 'Operating_Status']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = budget_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80056"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combine_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr1_predict_proba = lr_pipe_1.predict_proba(X_test)\n",
    "lr2_predict_proba = lr_pipe_2.predict_proba(X_test)\n",
    "combine_pred = np.concatenate([lr1_predict_proba, lr2_predict_proba], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_model = RandomForestClassifier()\n",
    "combined_model.fit(combine_pred, y_)\n",
    "\n",
    "final_prediction = combined_model.predict_proba(combine_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final blended Model codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "X_test = budget_test\n",
    "\n",
    "#create sub data sets for blendedmodels\n",
    "X_train = budget_train[word_predictors] \n",
    "y_train = label.fit_transform(budget_train['Operating_Status'])\n",
    "X_sub_1, X_sub_2, y_sub_1, y_sub_2 = train_test_split(X_train,y_train, test_size = .5, random_state = 42)\n",
    "X_test = budget_test\n",
    "\n",
    "#first layer models\n",
    "lr_pipe_1 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", LogisticRegression())])\n",
    "\n",
    "lr_pipe_2 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", LogisticRegression(C=10))])\n",
    "\n",
    "#fit models on first subset \n",
    "lr_pipe_1.fit(X_sub_1,y_sub_1)\n",
    "lr_pipe_2.fit(X_sub_1,y_sub_1)\n",
    "   \n",
    "#predict proba on second subset of data and blend the results together \n",
    "lr1_train_predict = lr_pipe_1.predict_proba(X_sub_2)\n",
    "lr2_train_predict = lr_pipe_2.predict_proba(X_sub_2)\n",
    "blended = np.concatenate([lr1_train_predict, lr2_train_predict], axis=1)\n",
    "\n",
    "\n",
    "# get predict_proba test_set and combine results together \n",
    "lr1_test_predict = lr_pipe_1.predict_proba(X_test)\n",
    "lr2_test_predict = lr_pipe_2.predict_proba(X_test)\n",
    "test_combine_pred = np.concatenate([lr1_test_predict, lr2_test_predict], axis=1)\n",
    "\n",
    "#fit blended predict_probas and y_sub_2 in blender model\n",
    "blender = RandomForestClassifier()\n",
    "blender.fit(blended, y_sub_2)\n",
    "\n",
    "# get predict proba of the blended result from blender model\n",
    "train_prediction = blender.predict_proba(blended)\n",
    "\n",
    "log_loss_score = log_loss(y_sub_2, train_prediction)\n",
    "\n",
    "# get predict_proba of blended test set from blender model\n",
    "test_blended_proba = blender.predict_proba(test_combine_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
