{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "budget_train = pd.read_csv('../data/train_cleaned.csv', index_col=0)\n",
    "budget_test = pd.read_csv('../data/test_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function                  0\n",
       "Use                       0\n",
       "Sharing                   0\n",
       "Reporting                 0\n",
       "Student_Type              0\n",
       "Position_Type             0\n",
       "Object_Type               0\n",
       "Pre_K                     0\n",
       "Operating_Status          0\n",
       "Object_Description        0\n",
       "Text_2                    0\n",
       "SubFund_Description       0\n",
       "Job_Title_Description     0\n",
       "Text_3                    0\n",
       "Text_4                    0\n",
       "Sub_Object_Description    0\n",
       "Location_Description      0\n",
       "FTE                       0\n",
       "Function_Description      0\n",
       "Facility_or_Department    0\n",
       "Position_Extra            0\n",
       "Total                     0\n",
       "Program_Description       0\n",
       "Fund_Description          0\n",
       "Text_1                    0\n",
       "combined_text             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                        0\n",
       "Object_Description        0\n",
       "Program_Description       0\n",
       "SubFund_Description       0\n",
       "Job_Title_Description     0\n",
       "Facility_or_Department    0\n",
       "Sub_Object_Description    0\n",
       "Location_Description      0\n",
       "FTE                       0\n",
       "Function_Description      0\n",
       "Position_Extra            0\n",
       "Text_4                    0\n",
       "Total                     0\n",
       "Text_2                    0\n",
       "Text_3                    0\n",
       "Fund_Description          0\n",
       "Text_1                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in budget_test[word_predictors]:\n",
    "    budget_test[col] = budget_test[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in budget_train[word_predictors]:\n",
    "    budget_train[col] = budget_train[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    The data is expected to be stored in a 2D data structure, where the first\n",
    "    index is over features and the second is over samples.  i.e.\n",
    "\n",
    "    >> len(data[key]) == n_samples\n",
    "\n",
    "    Please note that this is the opposite convention to scikit-learn feature\n",
    "    matrixes (where the first index corresponds to sample).\n",
    "\n",
    "    ItemSelector only requires that the collection implement getitem\n",
    "    (data[key]).  Examples include: a dict of lists, 2D numpy array, Pandas\n",
    "    DataFrame, numpy record array, etc.\n",
    "\n",
    "    >> data = {'a': [1, 5, 2, 5, 2, 8],\n",
    "               'b': [9, 4, 1, 4, 1, 3]}\n",
    "    >> ds = ItemSelector(key='a')\n",
    "    >> data['a'] == ds.transform(data)\n",
    "\n",
    "    Parameters\n",
    "     ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayCaster(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        return np.transpose(np.matrix(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Function',\n",
       " 'Use',\n",
       " 'Sharing',\n",
       " 'Reporting',\n",
       " 'Student_Type',\n",
       " 'Position_Type',\n",
       " 'Object_Type',\n",
       " 'Pre_K',\n",
       " 'Operating_Status']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400,000+ examples, 14 features\n",
    "X = budget_train[predictors] \n",
    "y = label.fit_transform(budget_train['Operating_Status'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .2, random_state=42)\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature union transformer list \n",
    "transformer_list = [\n",
    "    ('Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_2', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_2')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('SubFund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='SubFund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Job_Title_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Job_Title_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_3', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_3')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_4', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_4')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Sub_Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Sub_Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Location_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Location_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Function_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Function_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Facility_or_Department', Pipeline([\n",
    "                ('selector', ItemSelector(key='Facility_or_Department')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Position_Extra', Pipeline([\n",
    "                ('selector', ItemSelector(key='Position_Extra')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Program_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Program_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Fund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Fund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_1', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_1')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "#     ('FTE', Pipeline([\n",
    "#                 ('selector', ItemSelector(key='FTE')),\n",
    "#                 ('scaler', StandardScaler()),\n",
    "#                 ('caster', ArrayCaster()),\n",
    "#             ])),\n",
    "#     ('Total', Pipeline([\n",
    "#                 ('selector', ItemSelector(key='Total')),\n",
    "#                 ('scaler', StandardScaler()),\n",
    "#                 ('caster', ArrayCaster()),\n",
    "#             ])),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't include numerical columns in final feature union since it decreased scores and increased log loss- in general, in the original data, numerical features had a lot of missing values and some incorrect values for data that were there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipeline = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),\n",
    "                              n_estimators=200, \n",
    "                              learning_rate=.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = ada_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96681979008247432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = ada_model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72425482510972894"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ada log_loss\n",
    "log_loss(y_val, val_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipeline = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=100, max_depth=5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = forest_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90904718928490014"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = forest_model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27822697178971878"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_val, val_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", xgb.XGBClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_model = model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97277505222955396"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = xgbc_model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.099883956633913584"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgbc log_loss \n",
    "log_loss(y_val, val_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe_1 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=100)),\n",
    "])\n",
    "\n",
    "gb_pipe_1 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=100)),\n",
    "])\n",
    "\n",
    "lr_pipe_1 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=100)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_1, X_sub_2, y_sub_1, y_sub_2 = train_test_split(X_train, y_train, test_size = .5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in (rf_pipe_1, gb_pipe_1, lr_pipe_1):\n",
    "    model.fit(X_sub_1, y_sub_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985585090437\n",
      "0.985460177875\n",
      "0.985585090437\n"
     ]
    }
   ],
   "source": [
    "for model in (rf_pipe_1, gb_pipe_1, lr_pipe_1):\n",
    "    print(model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_preds = []\n",
    "for model in (rf_pipe_1, gb_pipe_1, lr_pipe_1):\n",
    "    layer_1_preds.append(model.predict(X_sub_2).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = np.concatenate(layer_1_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160111, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender.fit(blended, y_sub_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_val_preds = []\n",
    "for model in [rf_pipe_1, gb_pipe_1, lr_pipe_1]:\n",
    "    layer_1_val_preds.append(model.predict(X_val).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_val = np.concatenate(layer_1_val_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160111, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = blender.predict(blended_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = blender.predict_proba(blended_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90371957182024765"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1188189853011468"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_val, blended_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with different C for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98660924798810823"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_stat_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = op_stat_model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044086925832810243"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C=10\n",
    "log_loss(y_val, val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047490405186274731"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normal C\n",
    "log_loss(y_val, val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_eval(model, X_val, y_val):\n",
    "    preds = model.predict(X_val)\n",
    "    proba = model.predict_proba(X_val)\n",
    "    return {\n",
    "        'log_loss': log_loss(y_val, proba),\n",
    "        'accuracy': accuracy_score(y_val, preds),\n",
    "        'confmat': confusion_matrix(y_val, preds),\n",
    "        'clf_rep': classification_report(y_val, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "log_loss\n",
      "0.0474904051863\n",
      "------------------------------------------------------------\n",
      "accuracy\n",
      "0.984460877386\n",
      "------------------------------------------------------------\n",
      "confmat\n",
      "[[ 9158    25   495]\n",
      " [   35  1321   373]\n",
      " [  307     9 68333]]\n",
      "------------------------------------------------------------\n",
      "clf_rep\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.96      9678\n",
      "          1       0.97      0.76      0.86      1729\n",
      "          2       0.99      1.00      0.99     68649\n",
      "\n",
      "avg / total       0.98      0.98      0.98     80056\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = score_eval(op_stat_model, X_val, y_val)\n",
    "\n",
    "print('-'*60)\n",
    "for key, value in results.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
