{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_train = pd.read_csv('../data/budget_df_cleaned2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# budget_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "budget_test = pd.read_csv('../data/budget_test_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in budget_test[word_predictors[0:14]]:\n",
    "    budget_test[col] = budget_test[word_predictors[0:14]].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in budget_df[word_predictors]:\n",
    "    budget_train[col] = budget_train[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_test['FTE'] = np.clip(budget_test['FTE'],0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    The data is expected to be stored in a 2D data structure, where the first\n",
    "    index is over features and the second is over samples.  i.e.\n",
    "\n",
    "    >> len(data[key]) == n_samples\n",
    "\n",
    "    Please note that this is the opposite convention to scikit-learn feature\n",
    "    matrixes (where the first index corresponds to sample).\n",
    "\n",
    "    ItemSelector only requires that the collection implement getitem\n",
    "    (data[key]).  Examples include: a dict of lists, 2D numpy array, Pandas\n",
    "    DataFrame, numpy record array, etc.\n",
    "\n",
    "    >> data = {'a': [1, 5, 2, 5, 2, 8],\n",
    "               'b': [9, 4, 1, 4, 1, 3]}\n",
    "    >> ds = ItemSelector(key='a')\n",
    "    >> data['a'] == ds.transform(data)\n",
    "\n",
    "    Parameters\n",
    "     ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400,000+ examples, 14 features, return labels in {0, 1, 2}\n",
    "X = budget_train[word_predictors] \n",
    "y = label.fit_transform(budget_train['Operating_Status'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .2, random_state=42)\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature union transformer list \n",
    "transformer_list = [\n",
    "    ('Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Text_2', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_2')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('SubFund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='SubFund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Job_Title_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Job_Title_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Text_3', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_3')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Text_4', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_4')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Sub_Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Sub_Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Location_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Location_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Function_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Function_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Facility_or_Department', Pipeline([\n",
    "                ('selector', ItemSelector(key='Facility_or_Department')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Position_Extra', Pipeline([\n",
    "                ('selector', ItemSelector(key='Position_Extra')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Program_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Program_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Fund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Fund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Text_1', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_1')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "#     ('FTE', Pipeline([\n",
    "# #                 ('selector', ItemSelector(key='FTE')),\n",
    "# # #                 ('imputer', Imputer()),\n",
    "# #             ])),\n",
    "# #     ('Total', Pipeline([\n",
    "# #                 ('selector', ItemSelector(key='Total')),\n",
    "# # #                 ('imputer', Imputer()),\n",
    "# #             ])),\n",
    "   \n",
    "]\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = budget_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ops_model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98528203959140714"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ops_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba = Ops_model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Non-Operating', 'Operating, Not PreK-12', 'PreK-12 Operating']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047490405186274731"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_val, predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Non-Operating', 'Operating, Not PreK-12', 'PreK-12 Operating'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
