{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "budget_train = pd.read_csv('../data/train_cleaned.csv', index_col=0)\n",
    "budget_test = pd.read_csv('../data/test_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function                  0\n",
       "Use                       0\n",
       "Sharing                   0\n",
       "Reporting                 0\n",
       "Student_Type              0\n",
       "Position_Type             0\n",
       "Object_Type               0\n",
       "Pre_K                     0\n",
       "Operating_Status          0\n",
       "Object_Description        0\n",
       "Text_2                    0\n",
       "SubFund_Description       0\n",
       "Job_Title_Description     0\n",
       "Text_3                    0\n",
       "Text_4                    0\n",
       "Sub_Object_Description    0\n",
       "Location_Description      0\n",
       "FTE                       0\n",
       "Function_Description      0\n",
       "Facility_or_Department    0\n",
       "Position_Extra            0\n",
       "Total                     0\n",
       "Program_Description       0\n",
       "Fund_Description          0\n",
       "Text_1                    0\n",
       "combined_text             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                        0\n",
       "Object_Description        0\n",
       "Program_Description       0\n",
       "SubFund_Description       0\n",
       "Job_Title_Description     0\n",
       "Facility_or_Department    0\n",
       "Sub_Object_Description    0\n",
       "Location_Description      0\n",
       "FTE                       0\n",
       "Function_Description      0\n",
       "Position_Extra            0\n",
       "Text_4                    0\n",
       "Total                     0\n",
       "Text_2                    0\n",
       "Text_3                    0\n",
       "Fund_Description          0\n",
       "Text_1                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in budget_test[word_predictors]:\n",
    "    budget_test[col] = budget_test[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in budget_train[word_predictors]:\n",
    "    budget_train[col] = budget_train[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    The data is expected to be stored in a 2D data structure, where the first\n",
    "    index is over features and the second is over samples.  i.e.\n",
    "\n",
    "    >> len(data[key]) == n_samples\n",
    "\n",
    "    Please note that this is the opposite convention to scikit-learn feature\n",
    "    matrixes (where the first index corresponds to sample).\n",
    "\n",
    "    ItemSelector only requires that the collection implement getitem\n",
    "    (data[key]).  Examples include: a dict of lists, 2D numpy array, Pandas\n",
    "    DataFrame, numpy record array, etc.\n",
    "\n",
    "    >> data = {'a': [1, 5, 2, 5, 2, 8],\n",
    "               'b': [9, 4, 1, 4, 1, 3]}\n",
    "    >> ds = ItemSelector(key='a')\n",
    "    >> data['a'] == ds.transform(data)\n",
    "\n",
    "    Parameters\n",
    "     ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayCaster(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        return np.transpose(np.matrix(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature union transformer list \n",
    "transformer_list = [\n",
    "    ('Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Text_2', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_2')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('SubFund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='SubFund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Job_Title_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Job_Title_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Text_3', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_3')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Text_4', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_4')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Sub_Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Sub_Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Location_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Location_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Function_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Function_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Facility_or_Department', Pipeline([\n",
    "                ('selector', ItemSelector(key='Facility_or_Department')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Position_Extra', Pipeline([\n",
    "                ('selector', ItemSelector(key='Position_Extra')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Program_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Program_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Fund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Fund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "    ('Text_1', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_1')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)),\n",
    "            ])),\n",
    "#     ('FTE', Pipeline([\n",
    "#                 ('selector', ItemSelector(key='FTE')),\n",
    "#                 ('scaler', StandardScaler()),\n",
    "#                 ('caster', ArrayCaster()),\n",
    "#             ])),\n",
    "#     ('Total', Pipeline([\n",
    "#                 ('selector', ItemSelector(key='Total')),\n",
    "#                 ('scaler', StandardScaler()),\n",
    "#                 ('caster', ArrayCaster()),\n",
    "#             ])),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_pipe(target_name,X, y):\n",
    "     \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=42)\n",
    "        \n",
    "    pipeline = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", LogisticRegression())])\n",
    "\n",
    "    \n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "#   \n",
    "    val_proba = model.predict_proba(X_val)\n",
    "    \n",
    "    log_loss_score = log_loss(y_val, val_proba)\n",
    "    \n",
    "    results = {'target': target_name,\n",
    "               'train_score': model.score(X_train, y_train),\n",
    "               'val_score': model.score(X_val, y_val),\n",
    "              'log_loss': log_loss_score}\n",
    "    \n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = []\n",
    "for target in budget_train[targets]:\n",
    "    X = budget_train[word_predictors] \n",
    "    y = label.fit_transform(budget_train[target])\n",
    "    results = nlp_pipe(target,X, y)\n",
    "    model_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results = []\n",
    "for item in model_results:\n",
    "    scores = item[1]\n",
    "    score_results.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = pd.DataFrame(score_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results.to_pickle('baseline_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_loss</th>\n",
       "      <th>target</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.162338</td>\n",
       "      <td>Function</td>\n",
       "      <td>0.959334</td>\n",
       "      <td>0.955106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.122412</td>\n",
       "      <td>Use</td>\n",
       "      <td>0.967894</td>\n",
       "      <td>0.965187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098230</td>\n",
       "      <td>Sharing</td>\n",
       "      <td>0.972385</td>\n",
       "      <td>0.971095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064400</td>\n",
       "      <td>Reporting</td>\n",
       "      <td>0.981047</td>\n",
       "      <td>0.980301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079315</td>\n",
       "      <td>Student_Type</td>\n",
       "      <td>0.977956</td>\n",
       "      <td>0.975405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.070038</td>\n",
       "      <td>Position_Type</td>\n",
       "      <td>0.983090</td>\n",
       "      <td>0.981138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055530</td>\n",
       "      <td>Object_Type</td>\n",
       "      <td>0.985635</td>\n",
       "      <td>0.983949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.032124</td>\n",
       "      <td>Pre_K</td>\n",
       "      <td>0.989944</td>\n",
       "      <td>0.989183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.047490</td>\n",
       "      <td>Operating_Status</td>\n",
       "      <td>0.985282</td>\n",
       "      <td>0.984461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_loss            target  train_score  val_score\n",
       "0  0.162338          Function     0.959334   0.955106\n",
       "1  0.122412               Use     0.967894   0.965187\n",
       "2  0.098230           Sharing     0.972385   0.971095\n",
       "3  0.064400         Reporting     0.981047   0.980301\n",
       "4  0.079315      Student_Type     0.977956   0.975405\n",
       "5  0.070038     Position_Type     0.983090   0.981138\n",
       "6  0.055530       Object_Type     0.985635   0.983949\n",
       "7  0.032124             Pre_K     0.989944   0.989183\n",
       "8  0.047490  Operating_Status     0.985282   0.984461"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
