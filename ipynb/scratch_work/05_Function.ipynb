{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (6,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "budget_train = pd.read_csv('../data/train_cleaned.csv', index_col=0)\n",
    "budget_test = pd.read_csv('../data/test_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in budget_test[word_predictors]:\n",
    "    budget_test[col] = budget_test[word_predictors].loc[:,[col]].fillna(' ')\n",
    "\n",
    "for col in budget_train[word_predictors]:\n",
    "    budget_train[col] = budget_train[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    The data is expected to be stored in a 2D data structure, where the first\n",
    "    index is over features and the second is over samples.  i.e.\n",
    "\n",
    "    >> len(data[key]) == n_samples\n",
    "\n",
    "    Please note that this is the opposite convention to scikit-learn feature\n",
    "    matrixes (where the first index corresponds to sample).\n",
    "\n",
    "    ItemSelector only requires that the collection implement getitem\n",
    "    (data[key]).  Examples include: a dict of lists, 2D numpy array, Pandas\n",
    "    DataFrame, numpy record array, etc.\n",
    "\n",
    "    >> data = {'a': [1, 5, 2, 5, 2, 8],\n",
    "               'b': [9, 4, 1, 4, 1, 3]}\n",
    "    >> ds = ItemSelector(key='a')\n",
    "    >> data['a'] == ds.transform(data)\n",
    "\n",
    "    Parameters\n",
    "     ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    \n",
    "\n",
    "# feature union transformer list \n",
    "transformer_list = [\n",
    "    ('Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_2', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_2')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('SubFund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='SubFund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Job_Title_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Job_Title_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_3', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_3')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_4', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_4')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Sub_Object_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Sub_Object_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Location_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Location_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Function_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Function_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Facility_or_Department', Pipeline([\n",
    "                ('selector', ItemSelector(key='Facility_or_Department')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Position_Extra', Pipeline([\n",
    "                ('selector', ItemSelector(key='Position_Extra')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Program_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Program_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Fund_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Fund_Description')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "    ('Text_1', Pipeline([\n",
    "                ('selector', ItemSelector(key='Text_1')),\n",
    "                ('tfidf', TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=10)),\n",
    "            ])),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "X_test = budget_test\n",
    "\n",
    "#Example of blended model for Operating Status\n",
    "X_train = budget_train[word_predictors] \n",
    "y_train = label.fit_transform(budget_train['Function'])\n",
    "X_sub_1, X_sub_2, y_sub_1, y_sub_2 = train_test_split(X_train,y_train, test_size = .5, random_state = 42)\n",
    "X_test = budget_test\n",
    "\n",
    "lr_pipe_1 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", LogisticRegression())])\n",
    "\n",
    "lr_pipe_2 = Pipeline([\n",
    "    (\"union\", FeatureUnion(transformer_list=transformer_list)),\n",
    "    (\"clf\", LogisticRegression(C=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('Object_Description', Pipeline(steps=[('selector', ItemSelector(key='Object_Description')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit training data   \n",
    "lr_pipe_1.fit(X_sub_1,y_sub_1)\n",
    "lr_pipe_2.fit(X_sub_1,y_sub_1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1_train_predict = lr_pipe_1.predict_proba(X_sub_2)\n",
    "lr2_train_predict = lr_pipe_2.predict_proba(X_sub_2)\n",
    "blended = np.concatenate([lr1_train_predict, lr2_train_predict], axis=1)\n",
    "\n",
    "# blended.reshape(-1,1)\n",
    "\n",
    "# get predict_proba of 2 models for test set and combine them\n",
    "lr1_test_predict = lr_pipe_1.predict_proba(X_test)\n",
    "lr2_test_predict = lr_pipe_2.predict_proba(X_test)\n",
    "test_combine_pred = np.concatenate([lr1_test_predict, lr2_test_predict], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit blended predict_proba of training set to blender model\n",
    "blender = RandomForestClassifier()\n",
    "blender.fit(blended, y_sub_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = blender.predict_proba(blended)\n",
    "func_result = [{\"target\": \"Function\",\n",
    "             \"log_loss\": log_loss(y_sub_2, train_prediction)\n",
    "             }]\n",
    "func_result = pd.DataFrame(func_result)\n",
    "\n",
    "# fuc_result.to_csv('func_blended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find predict proba with blended model of blended test_proba    \n",
    "blended_proba = blender.predict_proba(test_combine_pred)\n",
    "\n",
    "func = pd.DataFrame(blended_proba,columns=label.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_loss</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068744</td>\n",
       "      <td>Function</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_loss    target\n",
       "0  0.068744  Function"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.to_pickle('func.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
