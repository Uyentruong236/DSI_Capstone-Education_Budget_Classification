{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_df = pd.read_csv('../data/budget_df_cleaned1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Function__Teacher Compensation</td>\n",
       "      <td>Use__Instruction</td>\n",
       "      <td>Sharing__School Reported</td>\n",
       "      <td>Reporting__School</td>\n",
       "      <td>Student_Type__NO_LABEL</td>\n",
       "      <td>Position_Type__Teacher</td>\n",
       "      <td>Object_Type__NO_LABEL</td>\n",
       "      <td>Pre_K__NO_LABEL</td>\n",
       "      <td>Operating_Status__PreK-12 Operating</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kindergarten</td>\n",
       "      <td>50471.810</td>\n",
       "      <td>kindergarten</td>\n",
       "      <td>general fund</td>\n",
       "      <td></td>\n",
       "      <td>teacher elementary             kindergar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Function__NO_LABEL</td>\n",
       "      <td>Use__NO_LABEL</td>\n",
       "      <td>Sharing__NO_LABEL</td>\n",
       "      <td>Reporting__NO_LABEL</td>\n",
       "      <td>Student_Type__NO_LABEL</td>\n",
       "      <td>Position_Type__NO_LABEL</td>\n",
       "      <td>Object_Type__NO_LABEL</td>\n",
       "      <td>Pre_K__NO_LABEL</td>\n",
       "      <td>Operating_Status__Non-Operating</td>\n",
       "      <td>contractor service</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0.420663</td>\n",
       "      <td>rgn gob</td>\n",
       "      <td></td>\n",
       "      <td>undesignated</td>\n",
       "      <td>3477.860</td>\n",
       "      <td>building improvement service</td>\n",
       "      <td></td>\n",
       "      <td>building improvement service</td>\n",
       "      <td>contractor service bond expenditure building f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Function__Teacher Compensation</td>\n",
       "      <td>Use__Instruction</td>\n",
       "      <td>Sharing__School Reported</td>\n",
       "      <td>Reporting__School</td>\n",
       "      <td>Student_Type__Unspecified</td>\n",
       "      <td>Position_Type__Teacher</td>\n",
       "      <td>Object_Type__Base Salary/Compensation</td>\n",
       "      <td>Pre_K__Non PreK</td>\n",
       "      <td>Operating_Status__PreK-12 Operating</td>\n",
       "      <td>personal service teacher</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>teacher</td>\n",
       "      <td>62237.130</td>\n",
       "      <td>instruction regular</td>\n",
       "      <td>general purpose school</td>\n",
       "      <td></td>\n",
       "      <td>personal service teacher     tcher 2nd grade  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Function__Substitute Compensation</td>\n",
       "      <td>Use__Instruction</td>\n",
       "      <td>Sharing__School Reported</td>\n",
       "      <td>Reporting__School</td>\n",
       "      <td>Student_Type__Unspecified</td>\n",
       "      <td>Position_Type__Substitute</td>\n",
       "      <td>Object_Type__Benefits</td>\n",
       "      <td>Pre_K__NO_LABEL</td>\n",
       "      <td>Operating_Status__PreK-12 Operating</td>\n",
       "      <td>employee benefit</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0.420663</td>\n",
       "      <td>unalloc budget school</td>\n",
       "      <td></td>\n",
       "      <td>professional instructional</td>\n",
       "      <td>22.300</td>\n",
       "      <td>general middle junior high sch</td>\n",
       "      <td></td>\n",
       "      <td>regular instruction</td>\n",
       "      <td>employee benefit teacher sub general fund teac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Function__Substitute Compensation</td>\n",
       "      <td>Use__Instruction</td>\n",
       "      <td>Sharing__School Reported</td>\n",
       "      <td>Reporting__School</td>\n",
       "      <td>Student_Type__Unspecified</td>\n",
       "      <td>Position_Type__Teacher</td>\n",
       "      <td>Object_Type__Substitute Compensation</td>\n",
       "      <td>Pre_K__NO_LABEL</td>\n",
       "      <td>Operating_Status__PreK-12 Operating</td>\n",
       "      <td>teacher coverage teacher</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0.420663</td>\n",
       "      <td>non project</td>\n",
       "      <td></td>\n",
       "      <td>professional instructional</td>\n",
       "      <td>54.166</td>\n",
       "      <td>general high school education</td>\n",
       "      <td></td>\n",
       "      <td>regular instruction</td>\n",
       "      <td>teacher coverage teacher teacher sub general f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Function               Use  \\\n",
       "0     Function__Teacher Compensation  Use__Instruction   \n",
       "1                 Function__NO_LABEL     Use__NO_LABEL   \n",
       "2     Function__Teacher Compensation  Use__Instruction   \n",
       "3  Function__Substitute Compensation  Use__Instruction   \n",
       "4  Function__Substitute Compensation  Use__Instruction   \n",
       "\n",
       "                    Sharing            Reporting               Student_Type  \\\n",
       "0  Sharing__School Reported    Reporting__School     Student_Type__NO_LABEL   \n",
       "1         Sharing__NO_LABEL  Reporting__NO_LABEL     Student_Type__NO_LABEL   \n",
       "2  Sharing__School Reported    Reporting__School  Student_Type__Unspecified   \n",
       "3  Sharing__School Reported    Reporting__School  Student_Type__Unspecified   \n",
       "4  Sharing__School Reported    Reporting__School  Student_Type__Unspecified   \n",
       "\n",
       "               Position_Type                            Object_Type  \\\n",
       "0     Position_Type__Teacher                  Object_Type__NO_LABEL   \n",
       "1    Position_Type__NO_LABEL                  Object_Type__NO_LABEL   \n",
       "2     Position_Type__Teacher  Object_Type__Base Salary/Compensation   \n",
       "3  Position_Type__Substitute                  Object_Type__Benefits   \n",
       "4     Position_Type__Teacher   Object_Type__Substitute Compensation   \n",
       "\n",
       "             Pre_K                     Operating_Status  \\\n",
       "0  Pre_K__NO_LABEL  Operating_Status__PreK-12 Operating   \n",
       "1  Pre_K__NO_LABEL      Operating_Status__Non-Operating   \n",
       "2  Pre_K__Non PreK  Operating_Status__PreK-12 Operating   \n",
       "3  Pre_K__NO_LABEL  Operating_Status__PreK-12 Operating   \n",
       "4  Pre_K__NO_LABEL  Operating_Status__PreK-12 Operating   \n",
       "\n",
       "         Object_Description  \\\n",
       "0                             \n",
       "1        contractor service   \n",
       "2  personal service teacher   \n",
       "3          employee benefit   \n",
       "4  teacher coverage teacher   \n",
       "\n",
       "                         ...                         Location_Description  \\\n",
       "0                        ...                                                \n",
       "1                        ...                                                \n",
       "2                        ...                                                \n",
       "3                        ...                                                \n",
       "4                        ...                                                \n",
       "\n",
       "        FTE   Function_Description Facility_or_Department  \\\n",
       "0  1.000000                                                 \n",
       "1  0.420663                rgn gob                          \n",
       "2  1.000000                                                 \n",
       "3  0.420663  unalloc budget school                          \n",
       "4  0.420663            non project                          \n",
       "\n",
       "               Position_Extra      Total             Program_Description  \\\n",
       "0                kindergarten  50471.810                    kindergarten   \n",
       "1                undesignated   3477.860    building improvement service   \n",
       "2                     teacher  62237.130             instruction regular   \n",
       "3  professional instructional     22.300  general middle junior high sch   \n",
       "4  professional instructional     54.166   general high school education   \n",
       "\n",
       "         Fund_Description                        Text_1  \\\n",
       "0            general fund                                 \n",
       "1                          building improvement service   \n",
       "2  general purpose school                                 \n",
       "3                                   regular instruction   \n",
       "4                                   regular instruction   \n",
       "\n",
       "                                       combined_text  \n",
       "0        teacher elementary             kindergar...  \n",
       "1  contractor service bond expenditure building f...  \n",
       "2  personal service teacher     tcher 2nd grade  ...  \n",
       "3  employee benefit teacher sub general fund teac...  \n",
       "4  teacher coverage teacher teacher sub general f...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in budget_df[word_predictors]:\n",
    "    budget_df[col] = budget_df[word_predictors].loc[:,[col]].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf(word_column):\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2), token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',min_df=100)\n",
    "    col_tfidf = tfidf.fit_transform(budget_df[word_column])\n",
    "    \n",
    "    return col_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Object_Description_tfidf = create_tfidf('Object_Description')\n",
    "Text_2_tfidf= create_tfidf('Text_2')\n",
    "SubFund_Description_tfidf = create_tfidf('SubFund_Description')\n",
    "Job_Title_Description_tfidf = create_tfidf('Job_Title_Description')\n",
    "Text_3_tfidf = create_tfidf('Text_3')\n",
    "Text_4_tfidf= create_tfidf('Text_4')\n",
    "Sub_Object_Description_tfidf= create_tfidf('Sub_Object_Description')\n",
    "Location_Description_tfidf= create_tfidf('Location_Description')\n",
    "Function_Description_tfidf= create_tfidf('Function_Description')\n",
    "Facility_or_Department_tfidf= create_tfidf('Facility_or_Department')\n",
    "Position_Extra_tfidf= create_tfidf('Position_Extra')\n",
    "Program_Description_tfidf= create_tfidf('Program_Description')\n",
    "Fund_Description_tfidf= create_tfidf('Fund_Description')\n",
    "Text_1_tfidf= create_tfidf('Text_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_predictors), len(tfidf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word_predictors.append('combined_tfidif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_text_tfidf= create_tfidf('combined_text')\n",
    "\n",
    "# combined_text_tfidf.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_list = [Object_Description_tfidf, Text_2_tfidf, SubFund_Description_tfidf, Job_Title_Description_tfidf, Text_3_tfidf,\\\n",
    "              Text_4_tfidf,Sub_Object_Description_tfidf, Location_Description_tfidf, Function_Description_tfidf,\\\n",
    "              Facility_or_Department_tfidf, Position_Extra_tfidf, Program_Description_tfidf,\\\n",
    "              Fund_Description_tfidf, Text_1_tfidf, combined_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "combined_tfidf = hstack([Object_Description_tfidf, Text_2_tfidf, SubFund_Description_tfidf, Job_Title_Description_tfidf,\\\n",
    "                         Text_3_tfidf, Text_4_tfidf,Sub_Object_Description_tfidf, Location_Description_tfidf,\\\n",
    "                         Function_Description_tfidf,Facility_or_Department_tfidf, Position_Extra_tfidf,\\ \n",
    "                         Program_Description_tfidf, Fund_Description_tfidf, Text_1_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400277, 4717)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budget_tfidf.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions for Operating_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_pipe(target_name, predictor_name, X, y):\n",
    "     \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=42)\n",
    "    \n",
    "    for predictor in word_predictors:\n",
    "        precitor_name = predictor\n",
    "        \n",
    "    nlp_pipe = Pipeline([\n",
    "    ('clf', LogisticRegression(random_state=42, multi_class='ovr'))])\n",
    "\n",
    "    \n",
    "    model = nlp_pipe.fit(X_train, y_train)\n",
    "    \n",
    "    results = {'target': target_name,\n",
    "               'predictor': predictor_name,\n",
    "               'train_score': nlp_pipe.score(X_train, y_train),\n",
    "               'val_score': nlp_pipe.score(X_val, y_val)}\n",
    "    \n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_status_results = []\n",
    "for tfidf, predictor in zip(tfidf_list, word_predictors):  \n",
    "    results = nlp_pipe('Operating Status', predictor, tfidf, le.fit_transform(budget_df['Operating_Status']))\n",
    "    op_status_results.append(results)\n",
    "    \n",
    "       y = le.fit_transform(budget_df[target])\n",
    "#     X = tfidf\n",
    "#     results = nlp_pipe(X, y, target)\n",
    "#     model_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.91974917322723992,\n",
       "   'val_score': 0.91823223743379634}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.87587634789723345,\n",
       "   'val_score': 0.8744378934745678}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.93400182998616577,\n",
       "   'val_score': 0.93290946337563707}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.86541170004465662,\n",
       "   'val_score': 0.8642450284800639}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.85856018187439298,\n",
       "   'val_score': 0.85751224143099836}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.85879751796415604,\n",
       "   'val_score': 0.85786199660237838}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.92003022912301191,\n",
       "   'val_score': 0.91899420405716004}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.87821223467542731,\n",
       "   'val_score': 0.87692365344259016}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.94203378291867179,\n",
       "   'val_score': 0.94042919956030779}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.85951889476330412,\n",
       "   'val_score': 0.85858648945737981}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.85900674846434177,\n",
       "   'val_score': 0.85778704906565406}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.86927778003316458,\n",
       "   'val_score': 0.86805486159688217}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.94142482847783249,\n",
       "   'val_score': 0.94069151593884281}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.93284325512692801,\n",
       "   'val_score': 0.932035075447187}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Operating Status',\n",
       "   'train_score': 0.98564116656933809,\n",
       "   'val_score': 0.98474817627660638})]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_status_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for item in op_status_results:\n",
    "    scores = item[1]\n",
    "    score_list.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>target</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Object_Description</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.919749</td>\n",
       "      <td>0.918232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text_2</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.875876</td>\n",
       "      <td>0.874438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SubFund_Description</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.934002</td>\n",
       "      <td>0.932909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job_Title_Description</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.865412</td>\n",
       "      <td>0.864245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Text_3</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.858560</td>\n",
       "      <td>0.857512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Text_4</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.858798</td>\n",
       "      <td>0.857862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sub_Object_Description</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.920030</td>\n",
       "      <td>0.918994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Location_Description</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.878212</td>\n",
       "      <td>0.876924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Function_Description</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.942034</td>\n",
       "      <td>0.940429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Facility_or_Department</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.859519</td>\n",
       "      <td>0.858586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Position_Extra</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.859007</td>\n",
       "      <td>0.857787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Program_Description</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.869278</td>\n",
       "      <td>0.868055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fund_Description</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.941425</td>\n",
       "      <td>0.940692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Text_1</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.932843</td>\n",
       "      <td>0.932035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>combined_tfidif</td>\n",
       "      <td>Operating Status</td>\n",
       "      <td>0.985641</td>\n",
       "      <td>0.984748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predictor            target  train_score  val_score\n",
       "0       Object_Description  Operating Status     0.919749   0.918232\n",
       "1                   Text_2  Operating Status     0.875876   0.874438\n",
       "2      SubFund_Description  Operating Status     0.934002   0.932909\n",
       "3    Job_Title_Description  Operating Status     0.865412   0.864245\n",
       "4                   Text_3  Operating Status     0.858560   0.857512\n",
       "5                   Text_4  Operating Status     0.858798   0.857862\n",
       "6   Sub_Object_Description  Operating Status     0.920030   0.918994\n",
       "7     Location_Description  Operating Status     0.878212   0.876924\n",
       "8     Function_Description  Operating Status     0.942034   0.940429\n",
       "9   Facility_or_Department  Operating Status     0.859519   0.858586\n",
       "10          Position_Extra  Operating Status     0.859007   0.857787\n",
       "11     Program_Description  Operating Status     0.869278   0.868055\n",
       "12        Fund_Description  Operating Status     0.941425   0.940692\n",
       "13                  Text_1  Operating Status     0.932843   0.932035\n",
       "14         combined_tfidif  Operating Status     0.985641   0.984748"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = []\n",
    "for target, (tfidf, predictor) in itertools.product(targets, zip(tfidf_list, word_predictors)):\n",
    "    X = tfidf\n",
    "    y = budget_df[target]\n",
    "    results = nlp_pipe(target, predictor, X, y)\n",
    "    model_results.append(results)\n",
    "    \n",
    "#        y = le.fit_transform(budget_df[target])\n",
    "#     X = tfidf\n",
    "#     results = nlp_pipe(X, y, target)\n",
    "#     model_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.53963044272549265,\n",
       "   'val_score': 0.53641201159188567}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.36372380324838161,\n",
       "   'val_score': 0.35866143699410413}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.38143657036858919,\n",
       "   'val_score': 0.37857249925052461}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.69019520893383013,\n",
       "   'val_score': 0.68819326471469966}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.26192535779976955,\n",
       "   'val_score': 0.26207904466873189}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.25093294943179867,\n",
       "   'val_score': 0.24863845308284202}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.34071781675780166,\n",
       "   'val_score': 0.33802588188268212}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.34004640545123527,\n",
       "   'val_score': 0.3360147896472469}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.48347235190696425,\n",
       "   'val_score': 0.4760542620165884}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.25688196589230561,\n",
       "   'val_score': 0.25356000799440392}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.45020782522070696,\n",
       "   'val_score': 0.44804886579394426}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.46115963662595522,\n",
       "   'val_score': 0.45932847007095035}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.34648258546441363,\n",
       "   'val_score': 0.34668232237433794}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.42911926450794918,\n",
       "   'val_score': 0.42833766363545517}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Function',\n",
       "   'train_score': 0.96024308212140985,\n",
       "   'val_score': 0.95610572599180577}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.68872747258924305,\n",
       "   'val_score': 0.68413360647546717}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.603239637625265,\n",
       "   'val_score': 0.5995428200259818}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.6500229528981547,\n",
       "   'val_score': 0.64604776656340557}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.74892964546360175,\n",
       "   'val_score': 0.7480138902768062}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.51210570199955652,\n",
       "   'val_score': 0.50808184271010293}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.53120813438219228,\n",
       "   'val_score': 0.52808034375936841}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.61048463404960951,\n",
       "   'val_score': 0.60621315079444393}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.6444393091021513,\n",
       "   'val_score': 0.64001448985710008}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.71865367980238648,\n",
       "   'val_score': 0.71345058459078647}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.54372761311719098,\n",
       "   'val_score': 0.53891026281602883}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.64022971635214432,\n",
       "   'val_score': 0.63756620365743977}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.69944194790472825,\n",
       "   'val_score': 0.69597531727790551}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.62580218036918256,\n",
       "   'val_score': 0.62232687119016683}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.68924274173149169,\n",
       "   'val_score': 0.68648196262616168}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Use',\n",
       "   'train_score': 0.96893707783062322,\n",
       "   'val_score': 0.966061257120016}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.73072659194743628,\n",
       "   'val_score': 0.72887728589987011}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.70558770349227562,\n",
       "   'val_score': 0.70513140801438989}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.73841815496172958,\n",
       "   'val_score': 0.73789597281902664}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.7263764712495433,\n",
       "   'val_score': 0.72541720795443188}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.63701318776719829,\n",
       "   'val_score': 0.63565504147097029}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.65029151742078128,\n",
       "   'val_score': 0.64887079044668727}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.71792293447337929,\n",
       "   'val_score': 0.71714799640251825}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.80102179432329546,\n",
       "   'val_score': 0.7997776556410513}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.77916813700538068,\n",
       "   'val_score': 0.77714349955031481}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.6639008684627179,\n",
       "   'val_score': 0.66169931048266217}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.66868194153412797,\n",
       "   'val_score': 0.66698311182172476}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.68956439458998631,\n",
       "   'val_score': 0.68937993404616771}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.73270647459098559,\n",
       "   'val_score': 0.73211252123513537}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.75180890697362135,\n",
       "   'val_score': 0.75139902068552011}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Sharing',\n",
       "   'train_score': 0.97312168783433939,\n",
       "   'val_score': 0.97180723493554511}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.74823012856745807,\n",
       "   'val_score': 0.74620265813930253}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.72408742712064478,\n",
       "   'val_score': 0.7239807135005496}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.74703720243207039,\n",
       "   'val_score': 0.74705206355551113}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.74204689886047448,\n",
       "   'val_score': 0.74114369941041269}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.69325247251117195,\n",
       "   'val_score': 0.69176576396522438}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.65817669671882861,\n",
       "   'val_score': 0.65702758069351452}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.72349408689623729,\n",
       "   'val_score': 0.72231937643649446}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.85835095137420714,\n",
       "   'val_score': 0.85678774857599682}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.79172196701652919,\n",
       "   'val_score': 0.78984710702508243}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.66717673107010467,\n",
       "   'val_score': 0.66537173978215247}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.6774758682285047,\n",
       "   'val_score': 0.67545218347156988}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.70317062278863662,\n",
       "   'val_score': 0.70320775457179974}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.7328782309717351,\n",
       "   'val_score': 0.73251224143099836}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.76411290952186151,\n",
       "   'val_score': 0.76285350254821627}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Reporting',\n",
       "   'train_score': 0.98153462764778077,\n",
       "   'val_score': 0.98081343059858095}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.72147673013325175,\n",
       "   'val_score': 0.71633606475467171}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.60661543121781525,\n",
       "   'val_score': 0.60290296792245424}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.74108818597156334,\n",
       "   'val_score': 0.73707154991505941}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.75431030444599201,\n",
       "   'val_score': 0.75116168681922657}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.56107500757289497,\n",
       "   'val_score': 0.55723493554511838}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.5792405869696241,\n",
       "   'val_score': 0.57615918856800241}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.63406210086159243,\n",
       "   'val_score': 0.63132057559708199}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.63204474409860689,\n",
       "   'val_score': 0.62853502548216245}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.7666830095465319,\n",
       "   'val_score': 0.76141700809433399}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.56708023521255635,\n",
       "   'val_score': 0.56393024882582188}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.6639133598358633,\n",
       "   'val_score': 0.66097481762766064}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.76071525602630685,\n",
       "   'val_score': 0.75991805735984808}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.70940694083148825,\n",
       "   'val_score': 0.70529379434395922}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.70428235499857905,\n",
       "   'val_score': 0.70268312181472969}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Student_Type',\n",
       "   'train_score': 0.97842739857785721,\n",
       "   'val_score': 0.9759668232237434}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.63871201451497561,\n",
       "   'val_score': 0.63807834515838913}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.36790216756552507,\n",
       "   'val_score': 0.36363295693014891}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.43311338107119768,\n",
       "   'val_score': 0.43305935844908566}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.87781563357806014,\n",
       "   'val_score': 0.87475017487758566}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.37233660503214966,\n",
       "   'val_score': 0.37247676626361548}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.30226000168633538,\n",
       "   'val_score': 0.30342510242830018}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.39402162881260128,\n",
       "   'val_score': 0.39202558209253524}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.36438272318180259,\n",
       "   'val_score': 0.36278355151394026}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.51267405947767319,\n",
       "   'val_score': 0.50672029579294497}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.29246364229703858,\n",
       "   'val_score': 0.29399420405715998}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.59736556940363061,\n",
       "   'val_score': 0.59826871190166886}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.52143675773918641,\n",
       "   'val_score': 0.52066053762366349}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.42763279110364405,\n",
       "   'val_score': 0.42733836314579793}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.49633846624674832,\n",
       "   'val_score': 0.49521584890576598}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Position_Type',\n",
       "   'train_score': 0.9835426158809073,\n",
       "   'val_score': 0.98167532727091034}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.85550916398362375,\n",
       "   'val_score': 0.85154142100529628}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.304330446785189,\n",
       "   'val_score': 0.30128909763165784}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.4797873968290649,\n",
       "   'val_score': 0.47672878984710704}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.54102323083120718,\n",
       "   'val_score': 0.53967222943939241}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.37089385143385351,\n",
       "   'val_score': 0.36880433696412512}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.27826719671726713,\n",
       "   'val_score': 0.27693114819626263}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.40973577622954149,\n",
       "   'val_score': 0.40896372539222542}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.35913322361743921,\n",
       "   'val_score': 0.35708753872289395}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.50058553311619158,\n",
       "   'val_score': 0.49855101428999699}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.28185846649657581,\n",
       "   'val_score': 0.28027880483661438}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.49336864228142441,\n",
       "   'val_score': 0.49036924153092837}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.47790119948410631,\n",
       "   'val_score': 0.47534226041770761}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.44982996118305796,\n",
       "   'val_score': 0.4480113920255821}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.49511743452178342,\n",
       "   'val_score': 0.49424153092835016}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Object_Type',\n",
       "   'train_score': 0.98606899609956877,\n",
       "   'val_score': 0.98452333366643352}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.93340536691847198,\n",
       "   'val_score': 0.93375886879184566}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.78517024180175565,\n",
       "   'val_score': 0.78395123413610468}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.86782253506172302,\n",
       "   'val_score': 0.86753022883981212}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.88821782456490983,\n",
       "   'val_score': 0.88736634355950839}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.76567120832175284,\n",
       "   'val_score': 0.76532677126011794}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.8869686872503677,\n",
       "   'val_score': 0.88525532127510742}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.86969624103353627,\n",
       "   'val_score': 0.86960377735585093}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.82453680426955134,\n",
       "   'val_score': 0.82194963525532128}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.86074929501812814,\n",
       "   'val_score': 0.8607724592785051}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.86916848051814211,\n",
       "   'val_score': 0.86892924952533224}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.91606734099262699,\n",
       "   'val_score': 0.91603377635655037}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.95430343419076202,\n",
       "   'val_score': 0.95429449385430198}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.95030307194094077,\n",
       "   'val_score': 0.94978515039472367}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.88434549888982916,\n",
       "   'val_score': 0.88330668532027579}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Pre_K',\n",
       "   'train_score': 0.99007872687924903,\n",
       "   'val_score': 0.98939492355351255}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Object_Description',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.91974917322723992,\n",
       "   'val_score': 0.91823223743379634}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_2',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.87587634789723345,\n",
       "   'val_score': 0.8744378934745678}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'SubFund_Description',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.93400182998616577,\n",
       "   'val_score': 0.93290946337563707}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Job_Title_Description',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.86541170004465662,\n",
       "   'val_score': 0.8642450284800639}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_3',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.85856018187439298,\n",
       "   'val_score': 0.85751224143099836}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_4',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.85879751796415604,\n",
       "   'val_score': 0.85786199660237838}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Sub_Object_Description',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.92003022912301191,\n",
       "   'val_score': 0.91899420405716004}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Location_Description',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.87821223467542731,\n",
       "   'val_score': 0.87692365344259016}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Function_Description',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.94203378291867179,\n",
       "   'val_score': 0.94042919956030779}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Facility_or_Department',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.85951889476330412,\n",
       "   'val_score': 0.85858648945737981}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Position_Extra',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.85900674846434177,\n",
       "   'val_score': 0.85778704906565406}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Program_Description',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.86927778003316458,\n",
       "   'val_score': 0.86805486159688217}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Fund_Description',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.94142482847783249,\n",
       "   'val_score': 0.94069151593884281}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'Text_1',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.93284325512692801,\n",
       "   'val_score': 0.932035075447187}),\n",
       " (Pipeline(steps=[('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))]),\n",
       "  {'predictor': 'combined_tfidif',\n",
       "   'target': 'Operating_Status',\n",
       "   'train_score': 0.98564116656933809,\n",
       "   'val_score': 0.98474817627660638})]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# model_results = []\n",
    "# for tfidf, target in itertools.product(tfidf_list, targets):  \n",
    "#     y = le.fit_transform(budget_df[target])\n",
    "#     X = tfidf\n",
    "#     results = nlp_pipe(X, y, target)\n",
    "#     model_results.append(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_tfidf #need to do combined tfidf for test set\n",
    "y = le.fit_transform(budget_df['Operating_Status'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_status_results[14][0].predict(X_val)\n",
    "p_status_results[14][0].predict_proba(X_val)\n",
    "list(le.classes_)\n",
    "list(le.inverse_transform([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out how to combine model of categorical columns and numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                     non_negative=True, norm=None, binary=False,\n",
    "                                                     ngram_range=(1, 2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running into memory issue for get_dummies for the 9 cat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
